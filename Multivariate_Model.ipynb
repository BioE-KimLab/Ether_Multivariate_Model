{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import sklearn as sk \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('YSI_CN_database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Define dataset#####\n",
    "x=data.iloc[:,4:12].to_numpy()\n",
    "y=np.array([i if ~np.isnan(i) else j for i,j in zip(data['YSI(exp)'],data['YSI(pred)-mean'])])\n",
    "exp_or_ML=['exp' if ~np.isnan(i) else 'ML' for i in data['YSI(exp)']]\n",
    "       \n",
    "\n",
    "####Leave one out validation#####\n",
    "y_pred_leave_one_out=[]\n",
    "for idx in np.arange(0,np.size(y)):\n",
    "    x_valid=x[idx,0:]\n",
    "    y_valid=y[idx]\n",
    "    x_train=np.delete(x,idx,0)\n",
    "    y_train=np.delete(y,idx,0)\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(x_train,y_train)\n",
    "    y_pred_leave_one_out.append(reg.predict([x_valid*0, x_valid])[1])\n",
    "    \n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(4,4))\n",
    "for idx in np.arange(0,np.size(y)):\n",
    "    if exp_or_ML[idx]=='exp': ax.plot(y_pred_leave_one_out[idx],y[idx],'o',color='C0')\n",
    "    else : ax.plot(y_pred_leave_one_out[idx],y[idx],'x',color='C0')\n",
    "\n",
    "ax.plot([0, 200],[0, 200],'k--')\n",
    "ax.set_xlim([0,100])\n",
    "ax.set_ylim([0,100])\n",
    "ax.set_xlabel('$YSI_{LRM, leave-one-out}$',fontsize=15)\n",
    "ax.set_ylabel('$YSI_{exp}$ or $CN_{ML}$',fontsize=15)\n",
    "Rsquared_leave_one_out=np.round(sk.metrics.r2_score(y, y_pred_leave_one_out)*100)/100\n",
    "MAE_leave_one_out=np.round(np.mean(np.abs(np.array(y)-np.array(y_pred_leave_one_out)))*100)/100\n",
    "ax.text(5,90,r'$Q^2$='+str(Rsquared_leave_one_out),fontsize=15)\n",
    "ax.grid()\n",
    "\n",
    "####Fitting to entire dataset#####\n",
    "reg = LinearRegression()\n",
    "reg.fit(x,y)\n",
    "y_pred=reg.predict(x)\n",
    "x2 = sm.add_constant(x)\n",
    "est = sm.OLS(y, x2)\n",
    "est_YSI = est.fit()\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(4,4))\n",
    "for idx in np.arange(0,np.size(y)):\n",
    "    if exp_or_ML[idx]=='exp': ax.plot(y_pred[idx],y[idx],'o',color='C0')\n",
    "    else : ax.plot(y_pred[idx],y[idx],'x',color='C0')\n",
    " \n",
    "ax.plot([0, 200],[0, 200],'k--')\n",
    "ax.set_xlim([0,100])\n",
    "ax.set_ylim([0,100])\n",
    "ax.set_xlabel('$YSI_{LRM}$',fontsize=15)\n",
    "ax.set_ylabel('$YSI_{exp}$ or $CN_{ML}$',fontsize=15)\n",
    "Rsquared=np.round(sk.metrics.r2_score(y, y_pred)*100)/100\n",
    "MAE=np.round(np.mean(np.abs(y-y_pred))*100)/100\n",
    "ax.text(5,90,r'$R^2$='+str(Rsquared),fontsize=15)\n",
    "ax.text(5,83,r'$Q^2$='+str(Rsquared_leave_one_out),fontsize=15)\n",
    "ax.text(5,76,r'$MAE$='+str(MAE),fontsize=15)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Define dataset#####\n",
    "x=data.iloc[:,4:12].to_numpy()\n",
    "y=np.array([i if ~np.isnan(i) else j for i,j in zip(data['CN(exp)'],data['CN(pred)-mean'])])\n",
    "exp_or_ML=['exp' if ~np.isnan(i) else 'ML' for i in data['CN(exp)']]\n",
    "       \n",
    "\n",
    "####Leave one out validation#####\n",
    "y_pred_leave_one_out=[]\n",
    "for idx in np.arange(0,np.size(y)):\n",
    "    x_valid=x[idx,0:]\n",
    "    y_valid=y[idx]\n",
    "    x_train=np.delete(x,idx,0)\n",
    "    y_train=np.delete(y,idx,0)\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(x_train,y_train)\n",
    "    y_pred_leave_one_out.append(reg.predict([x_valid*0, x_valid])[1])\n",
    "    \n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(4,4))\n",
    "for idx in np.arange(0,np.size(y)):\n",
    "    if exp_or_ML[idx]=='exp': ax.plot(y_pred_leave_one_out[idx],y[idx],'o',color='C3')\n",
    "    else : ax.plot(y_pred_leave_one_out[idx],y[idx],'x',color='C3')\n",
    "\n",
    "ax.plot([0, 200],[0, 200],'k--')\n",
    "ax.set_xlim([0,120])\n",
    "ax.set_ylim([0,120])\n",
    "ax.set_xlabel('$CN_{LRM, leave-one-out}$',fontsize=15)\n",
    "ax.set_ylabel('$CN_{exp}$ or $CN_{ML}$',fontsize=15)\n",
    "Rsquared_leave_one_out=np.round(sk.metrics.r2_score(y, y_pred_leave_one_out)*100)/100\n",
    "MAE_leave_one_out=np.round(np.mean(np.abs(np.array(y)-np.array(y_pred_leave_one_out)))*100)/100\n",
    "ax.text(6,90*1.2/1,r'$Q^2$='+str(Rsquared_leave_one_out),fontsize=15)\n",
    "ax.grid()\n",
    "\n",
    "####Fitting to entire dataset#####\n",
    "reg = LinearRegression()\n",
    "reg.fit(x,y)\n",
    "y_pred=reg.predict(x)\n",
    "x2 = sm.add_constant(x)\n",
    "est = sm.OLS(y, x2)\n",
    "est_CN = est.fit()\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(4,4))\n",
    "for idx in np.arange(0,np.size(y)):\n",
    "    if exp_or_ML[idx]=='exp': ax.plot(y_pred[idx],y[idx],'o',color='C3')\n",
    "    else : ax.plot(y_pred[idx],y[idx],'x',color='C3')\n",
    " \n",
    "ax.plot([0, 200],[0, 200],'k--')\n",
    "ax.set_xlim([0,120])\n",
    "ax.set_ylim([0,120])\n",
    "ax.set_xlabel('$CN_{LRM}$',fontsize=15)\n",
    "ax.set_ylabel('$CN_{exp}$ or $CN_{ML}$',fontsize=15)\n",
    "Rsquared=np.round(sk.metrics.r2_score(y, y_pred)*100)/100\n",
    "MAE=np.round(np.mean(np.abs(y-y_pred))*100)/100\n",
    "ax.text(6,90*1.2/1,r'$R^2$='+str(Rsquared),fontsize=15)\n",
    "ax.text(6,83*1.2/1,r'$Q^2$='+str(Rsquared_leave_one_out),fontsize=15)\n",
    "ax.text(6,76*1.2/1,r'$MAE$='+str(MAE),fontsize=15)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(8,4))\n",
    "ax.bar(np.array([0,1,2,3,5,6,7,8])-0.2,est_YSI.params[1:],color='C0',width=0.4)\n",
    "ax.errorbar(np.array([0,1,2,3,5,6,7,8])-0.2,est_YSI.params[1:],est_YSI.bse[1:], fmt='k.')\n",
    "ax.bar(np.array([0,1,2,3,5,6,7,8])+0.2,est_CN.params[1:],color='C3',width=0.4)\n",
    "ax.errorbar(np.array([0,1,2,3,5,6,7,8])+0.2,est_CN.params[1:],est_CN.bse[1:], fmt='k.')\n",
    "\n",
    "ax.plot([-1,10],[0,0],'k-')\n",
    "ax.set_xlim([-0.5,8.5])\n",
    "ax.set_ylim([-40,40])\n",
    "ax.set_xticks([0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5])\n",
    "ax.set_xticklabels([])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-issue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
